{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phase5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RIuPy47Dr0s",
        "colab_type": "text"
      },
      "source": [
        "**Import all the libraries.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10ppYZc-Plsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu=='2.0.0-beta1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXmheFQdDvRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import random\n",
        "import IPython.display as display\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "from datetime import datetime\n",
        "import io\n",
        "import itertools\n",
        "from packaging import version\n",
        "from six.moves import range\n",
        "import glob\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "%reload_ext tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK_Y7uvJsPjt",
        "colab_type": "text"
      },
      "source": [
        "**Mount to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N29KRFOGsUFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9CkwdXhD4ek",
        "colab_type": "text"
      },
      "source": [
        "**Define all the functions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyoDwZ3D-b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downloadUnzip(fileName, sourceURL, dest_dir):\n",
        "    ''' \n",
        "        This function downloads the files from the source and unzips thems and stores them to a specified destination.\n",
        "        \n",
        "        Args:\n",
        "            fileName(str): Name of file from source\n",
        "            sourceURL(str): url of the source to download from\n",
        "            dest_dir(str): Path on local to store the downloaded data\n",
        "            \n",
        "        Returns: Path of saved files on local to access\n",
        "    '''\n",
        "    \n",
        "    data_root = tf.keras.utils.get_file(fileName, sourceURL, untar=True, cache_subdir=dest_dir)\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    return data_root\n",
        "\n",
        "def get_all_paths(data_root):\n",
        "    ''' \n",
        "        This function allows us to get all image paths and randomly shuffles them.\n",
        "        \n",
        "        Args:\n",
        "            data_root(str): root directory where data has been downloaded.\n",
        "            \n",
        "        Returns: Path all images\n",
        "    '''\n",
        "    all_image_paths = list(data_root.glob('*/*'))\n",
        "    all_image_paths = [str(path) for path in all_image_paths]\n",
        "    random.shuffle(all_image_paths)\n",
        "    return all_image_paths\n",
        "\n",
        "def get_path_and_label(data_root):\n",
        "    ''' \n",
        "        This function helps us get the path and label of each image.\n",
        "        \n",
        "        Args:\n",
        "            data_root(str): root directory where data has been downloaded.\n",
        "            \n",
        "        Returns: Path and label\n",
        "    '''\n",
        "    all_image_paths = get_all_paths(data_root)\n",
        "    X = [p.rsplit('/', 2)[1] + '/' + p.rsplit('/', 1)[1] for p in all_image_paths]\n",
        "    y = [p.rsplit('/', 1)[0].rsplit('/', 1)[1] for p in all_image_paths]\n",
        "    return X, y\n",
        "\n",
        "def caption_image(image_path):\n",
        "    ''' \n",
        "        This function helps us caption each image. \n",
        "        \n",
        "        Args:\n",
        "            image_path(str): path of image to be captioned\n",
        "            \n",
        "        Returns: Path and caption\n",
        "    '''\n",
        "    image_rel = pathlib.Path(image_path).relative_to(data_root)\n",
        "    return image_rel, str(image_rel).split('/')[0]\n",
        "\n",
        "def display_image_and_caption(data_root):\n",
        "    ''' \n",
        "        This function helps display the image. \n",
        "        \n",
        "        Args:\n",
        "            data_root(str): root directory where data has been downloaded.\n",
        "    '''\n",
        "    for n in range(3):\n",
        "        all_image_paths = get_all_paths(data_root)\n",
        "        image_path = random.choice(all_image_paths)\n",
        "        display.display(display.Image(image_path))\n",
        "        imPath, label = caption_image(image_path)\n",
        "        print(label)\n",
        "        print()\n",
        "\n",
        "def split_data(data_root, test_size, valid_size):\n",
        "    ''' \n",
        "        This function helps us split data into train, test and validation with ratio of 60:20:20\n",
        "\n",
        "        Args:\n",
        "            data_root(str): root directory where data has been downloaded.\n",
        "            \n",
        "        Returns: A list of list of all the paths for each set of dataset.\n",
        "    '''\n",
        "    X, y = get_path_and_label(data_root)\n",
        "    X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=None)\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_temp, y_train_temp, test_size=valid_size, stratify=y_train_temp, random_state=None)\n",
        "    X_data = [X_train, X_test, X_valid]\n",
        "    return X_data\n",
        "\n",
        "def write_dataset_to_file(filenames, X_data, root_file):\n",
        "    ''' \n",
        "        This function writes all the datasets (train, test, validation) to files.\n",
        "\n",
        "        Args:\n",
        "            data_root(str): root directory where data has been downloaded.\n",
        "            filenames(list): list filenames ['trainData', 'testData', 'validataionData']\n",
        "    ''' \n",
        "    for d, l in zip(X_data, filenames):\n",
        "        with open(root_file+l+'.txt', 'w') as f:\n",
        "            for item in d:\n",
        "                f.write(\"%s\\n\" % item)\n",
        "\n",
        "def class_dictionary(data_root):\n",
        "    ''' \n",
        "        This function make the class labels a dictionary as follows:\n",
        "        {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n",
        "        \n",
        "        Args:\n",
        "            data_root(str): root directory where data has been downloaded.\n",
        "    '''\n",
        "    all_image_paths = get_all_paths(data_root)\n",
        "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "    label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                        for path in all_image_paths]\n",
        "    return label_to_index\n",
        "\n",
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.Example.\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def image_example(image_string, label, filename):\n",
        "    '''\n",
        "        This function Create a dictionary with features that may be relevant.\n",
        "        \n",
        "        Args:\n",
        "            image_string(bytes): image as bytes\n",
        "            label(str): Label of image\n",
        "            filename(str): filename of image\n",
        "            \n",
        "        Returns: Tfrecords \n",
        "    '''\n",
        "    image_shape = tf.image.decode_jpeg(image_string).shape\n",
        "    for lab, val in label_to_index.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
        "        if lab == label:\n",
        "            label_no = val\n",
        "    feature = {\n",
        "        'height': _int64_feature(image_shape[0]),\n",
        "        'width': _int64_feature(image_shape[1]),\n",
        "        'depth': _int64_feature(image_shape[2]),\n",
        "        'label_num': _int64_feature(label_no),\n",
        "        'image_raw': _bytes_feature(image_string),\n",
        "        'filename' : _bytes_feature(str.encode(filename)),\n",
        "        'label': _bytes_feature(str.encode(label)),\n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "def write_tfrecords(data_dir, split_path, output_path):\n",
        "    '''\n",
        "        This function writes to tfrecords\n",
        "        \n",
        "        Args:\n",
        "            data_dir(str): path of directory where images are\n",
        "            split_path(str): path where split(train, test, validation) data path file is\n",
        "            output_path(str): path of where to store the tfrecords\n",
        "    '''\n",
        "    with tf.io.TFRecordWriter(output_path) as writer:\n",
        "        f = open(split_path, \"r\")\n",
        "        for line in f:\n",
        "            label = line.split('/')[0]\n",
        "            image_string = open(data_dir+line.rstrip('\\n'), 'rb').read()\n",
        "            tf_example = image_example(image_string, label, line)\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "def augment(image, random_preprocessing):\n",
        "  '''\n",
        "    This function adds different augmentations to our training images to add more variety to data.\n",
        "    \n",
        "    Args:\n",
        "      image(tensor): The image we want to add the augmentation to.\n",
        "      random_preprocessing(list): A list of dictionaries of different augmentations.\n",
        "      \n",
        "   Returns: Tensor of augmented image.\n",
        "  '''\n",
        "  selected_preprocessing_key = random.choice(random_preprocessing)\n",
        "  selected_preprocessing = selected_preprocessing_key\n",
        "  selected_preprocessing = [*selected_preprocessing]\n",
        "  if selected_preprocessing[0] == 'random_flip':\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "  elif selected_preprocessing[0] == 'random_crop':\n",
        "    vals = selected_preprocessing_key.get('random_crop')\n",
        "    image = tf.image.random_crop(image, [vals[0], vals[1], 3])\n",
        "  elif selected_preprocessing[0] == 'random_brightness':\n",
        "    image = tf.image.random_brightness(image, 1000.)\n",
        "  elif selected_preprocessing[0] == 'random_salt_pepper':\n",
        "    vals = selected_preprocessing_key.get('random_salt_pepper')\n",
        "    image = add_salt_pepper_noise(image, vals[0], vals[1])\n",
        "  else:\n",
        "    return image\n",
        "    \n",
        "  return image\n",
        "  \n",
        "def add_salt_pepper_noise(image, amount, salt_vs_pepper):\n",
        "    '''\n",
        "        This function adds salt and pepper noise to the images, one kind of augmentation.\n",
        "        \n",
        "        Args:\n",
        "          image(tensor): The image we want to add the augmentation to.\n",
        "          amount(float): How much percentage of the image we want to add the salt pepper to.\n",
        "          salt_vs_pepper(float): Percentage of salt vs pepper we want to add.\n",
        "          \n",
        "        Returns: Tensor of image with salt pepper augmentation.\n",
        "    '''\n",
        "    image_numpy = image.numpy()\n",
        "    row, col, ch = image_numpy.shape\n",
        "    salt_vs_pepper = salt_vs_pepper\n",
        "    amount = amount\n",
        "    num_salt = np.ceil(amount * row * salt_vs_pepper)\n",
        "    num_pepper = np.ceil(amount * row * (1.0 - salt_vs_pepper))\n",
        "    #print(X_img.shape)\n",
        "\n",
        "    salt_coords = []\n",
        "    pepper_coords = []\n",
        "       \n",
        "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image_numpy.shape]\n",
        "    image_numpy[coords[0], coords[1], :] = 1\n",
        "\n",
        "    # Add Pepper noise\n",
        "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image_numpy.shape]\n",
        "    image_numpy[coords[0], coords[1], :] = 0 \n",
        "        \n",
        "    return tf.convert_to_tensor(image_numpy)\n",
        "\n",
        "def preprocess(image, h, w, is_training=False):\n",
        "  '''\n",
        "      This function is for preprocessing images.\n",
        "\n",
        "      Args: \n",
        "          image(tensor): Image we would like to preprocess on.\n",
        "          h(int): Height we would like to resize the image to.\n",
        "          w(int): Height we would like to resize the image to.\n",
        "          is_training(bool): If is_training is True, we add augmentation to images or else we just resize the images.\n",
        "\n",
        "     Returns: Tensor of preprocessed image.\n",
        "\n",
        "  '''\n",
        "\n",
        "  if is_training:\n",
        "    amount = 0.004\n",
        "    salt_vs_pepper = 0.2\n",
        "    random_preprocessing = [{'normal': ['']}, {'random_flip': ['']}, {'random_crop':[h, w]}, {'random_brigthness': ['']}, {'random_salt_pepper': [amount, salt_vs_pepper]}]\n",
        "    image = augment(image, random_preprocessing)\n",
        "\n",
        "  image = tf.image.resize(image, (h, w))\n",
        "  image = image/255.\n",
        "\n",
        "  return image\n",
        "  \n",
        "def create_image_feature_description():\n",
        "    '''\n",
        "        This function create a dictionary describing the features.\n",
        "    \n",
        "        Returns: Dictionary of image feature descriptions\n",
        "    '''\n",
        "    image_feature_description = {\n",
        "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'label_num': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "        'filename' : tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    return image_feature_description\n",
        "\n",
        "def parse_fn(example_proto):\n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "    image_feature_description = create_image_feature_description()\n",
        "    parsed = tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "    image = tf.image.decode_image(parsed[\"image_raw\"])\n",
        "    image = tf.reshape(image, (parsed['height'], parsed['width'], 3))\n",
        "    image = preprocess(image,160, 160, is_training=False)\n",
        "    labs = tf.one_hot(parsed[\"label_num\"], 5)\n",
        "    return image, labs\n",
        "\n",
        "def parse_fn_training(example_proto):\n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "    image_feature_description = create_image_feature_description()\n",
        "    parsed = tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "    image = tf.image.decode_image(parsed[\"image_raw\"])\n",
        "    image = tf.reshape(image, (parsed['height'], parsed['width'], 3))\n",
        "    #import pdb; pdb.set_trace()\n",
        "\n",
        "    image = preprocess(image,160, 160, is_training=True)\n",
        "    labs = tf.one_hot(parsed[\"label_num\"], 5)\n",
        "    return image, labs\n",
        "  \n",
        "def parse_fn_predict(example_proto):\n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "    image_feature_description = create_image_feature_description()\n",
        "    parsed = tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "    image = tf.image.decode_image(parsed[\"image_raw\"])\n",
        "    image = tf.reshape(image, (parsed['height'], parsed['width'], 3))\n",
        "    image = preprocess(image,160, 160, is_training=False)\n",
        "    labs = tf.one_hot(parsed[\"label_num\"], 5)\n",
        "    filenames = parsed[\"filename\"]\n",
        "    return image, labs, filenames\n",
        "\n",
        "\n",
        "def make_dataset(datasetPath, shuffle_buffer_size, batch_size, is_training=True, is_predict=False):\n",
        "    '''\n",
        "        This function makes dataset for each split data.\n",
        "        \n",
        "        Args:\n",
        "            datasetPath(str): path of where tfrecords are saved\n",
        "            shuffle_buffer_size(int): size of shuffle buffer\n",
        "            batch_size(int): size of batch\n",
        "        \n",
        "        Returns: dataset\n",
        "    '''\n",
        "    dataset = tf.data.TFRecordDataset(datasetPath)\n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
        "      dataset = dataset.repeat()\n",
        "      dataset = dataset.map(map_func=parse_fn_training)\n",
        "    elif is_predict:\n",
        "      dataset = dataset.map(map_func=parse_fn_predict)\n",
        "    else:\n",
        "      dataset = dataset.map(map_func=parse_fn)\n",
        "    dataset = dataset.batch(batch_size=batch_size)\n",
        "    return dataset\n",
        "  \n",
        "def create_callbacks(log_dir, checkpoint_path):\n",
        "    '''\n",
        "        This function creates model for logistic regression.\n",
        "        \n",
        "        Args:\n",
        "            log_dir(str): path of log directory \n",
        "            checkpoint_path(str): path where to store checkpoint.\n",
        "    '''\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        # Stop training when `val_loss` is no longer improving\n",
        "        monitor='val_loss',\n",
        "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "        min_delta=1e-1,\n",
        "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "        patience=1,\n",
        "        verbose=1)\n",
        "    return tensorboard_callback, cp_callback, early_stop_callback\n",
        "  \n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def plot_image_grid(actual_image, actual_label, predicted_label):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(actual_image, interpolation='nearest', cmap=plt.cm.binary)\n",
        "  plt.title('Actual: ' + str(actual_label) + ' ' + 'Predicted: ' + str(predicted_label))\n",
        "  plt.tight_layout()\n",
        "  return figure\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Normalize the confusion matrix.\n",
        "  cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure\n",
        "\n",
        "def accuracy(confusion_matrix):\n",
        "    '''\n",
        "      This function calculates the accuracy for the confusion matrix.\n",
        "      \n",
        "      Args:\n",
        "        confusion_matrix(list): confusion matrix\n",
        "        \n",
        "      Returns: The accuracy of the confusion matrix.\n",
        "    '''\n",
        "    diagonal_sum = confusion_matrix.trace()\n",
        "    sum_of_all_elements = confusion_matrix.sum()\n",
        "    return diagonal_sum / sum_of_all_elements \n",
        "  \n",
        "class ConfusionMatrixLogger(tf.keras.callbacks.Callback):\n",
        "  '''\n",
        "      ConfusionMatrixLogger logs and builds the confusion matrix.\n",
        "      \n",
        "      Arguments:\n",
        "          ds_valid: dataset onto which we want to make predictions on to evaluate and contruct the confusion matrix on.\n",
        "          file_writer_cm: Path to create a file with summary of confusion matrix.\n",
        "          class_names: class names present in our dataset\n",
        "          val_steps_per_epoch: number of steps to take per epoch.\n",
        "  '''\n",
        "  def __init__(self, ds_valid, file_writer_cm, class_names, val_steps_per_epoch):\n",
        "    self.ds_valid = ds_valid\n",
        "    self.file_writer_cm = file_writer_cm\n",
        "    self.class_names = class_names\n",
        "    self.val_steps_per_epoch = val_steps_per_epoch\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    test_labels = []\n",
        "    test_images = []\n",
        "    for test_image, test_label in self.ds_valid.take(self.val_steps_per_epoch):\n",
        "      test_labels.append(np.argmax(test_label.numpy(), axis=1))\n",
        "      test_images.append(test_image)\n",
        "\n",
        "    flattened_test_labels = [y for x in test_labels for y in x]\n",
        "    \n",
        "    # Use the model to predict the values from the validation dataset.\n",
        "    test_pred_raw = self.model.predict(self.ds_valid, steps=self.val_steps_per_epoch)\n",
        "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "    # Calculate the confusion matrix.\n",
        "    cm = sklearn.metrics.confusion_matrix(flattened_test_labels, test_pred)\n",
        "    # Log the confusion matrix as an image summary.\n",
        "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    acc = accuracy(cm)\n",
        "    headings = []\n",
        "    headings = list(class_names)\n",
        "    headings = tf.convert_to_tensor(headings)\n",
        "    headings = tf.reshape(headings, (1,-1))\n",
        "    accuracy_head = []\n",
        "    acc= tf.as_string(acc)\n",
        "    accuracy_head = [acc] + ['']*(len(class_names)-1)\n",
        "    acc_tensor = tf.convert_to_tensor(accuracy_head)\n",
        "    acc_tensor = tf.reshape(acc_tensor, (1,-1))\n",
        "    col_tensor = list(class_names)\n",
        "    col_tensor.insert(0, 'True/Predicted')\n",
        "    col_tensor.append('Accuracy')\n",
        "    col_tensor = tf.convert_to_tensor(col_tensor)\n",
        "    col_tensor = tf.reshape(col_tensor, (-1,1))\n",
        "    \n",
        "    updated_cm = tf.concat([headings, tf.as_string(cm)], 0)\n",
        "    updated_cm = tf.concat([updated_cm, acc_tensor], 0)\n",
        "    updated_cm = tf.concat([col_tensor, updated_cm], 1)\n",
        "    \n",
        "    r = random.randint(0,7)\n",
        "    actual_label = flattened_test_labels[r]\n",
        "    predicted_label = test_pred[r]\n",
        "    actual_image =  test_images[0][r]\n",
        "    \n",
        "    figure = plot_image_grid(actual_image, actual_label, predicted_label)\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with self.file_writer_cm.as_default():\n",
        "      tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "      #' '.join(str(r) for v in cm for r in v)\n",
        "      tf.summary.text('Confusion Matrix2', updated_cm, step=epoch)\n",
        "      tf.summary.image('True and Predicted labels', plot_to_image(figure), max_outputs=10, step=epoch)\n",
        "      \n",
        "def evaluate_model(model ,model_path, dataset_eval, dataset_predict, steps, file_to_write):\n",
        "  '''\n",
        "      This function evaluates the model.\n",
        "      \n",
        "      Args:\n",
        "        model(): The model that has been fit and compiled, which needs to be evaluated.\n",
        "        file_path(str): path where the data is that we want to evluate our model on.\n",
        "        steps(int): number of steps to take per epoch.\n",
        "        \n",
        "      Returns:\n",
        "        Accuracy, precision and recall.\n",
        "  '''\n",
        "  if(model):\n",
        "    model.load_weights(model_path)\n",
        "\n",
        "  else:\n",
        "    model = load_model(model_path)\n",
        "\n",
        "  loss, accuracy, precision, recall = model.evaluate(dataset_eval, steps=steps)\n",
        "  \n",
        "  predicted_classes = [] \n",
        "\n",
        "  for image, label, filename in dataset_predict:\n",
        "    labels = np.argmax(label.numpy(), axis=1)\n",
        "    classes = model.predict_classes(image)\n",
        "    probabilities = model.predict_proba(image)\n",
        "    for clas, fname, prob, actual in zip(classes, filename, probabilities, labels):\n",
        "      for name, lab in label_to_index.items():    \n",
        "        if lab == clas:\n",
        "          predicted_label = name\n",
        "        if lab == actual:\n",
        "          actual_label = name\n",
        "      predicted_classes.append(tuple((fname, actual_label, predicted_label, max(prob))))\n",
        "            \n",
        "  with open(file_to_write + 'predicted_classes_evaluate.txt', 'w') as fp:\n",
        "    fp.write('\\n'.join('%s %s %s %s' % x for x in predicted_classes))\n",
        "        \n",
        "  return accuracy, precision, recall\n",
        "  \n",
        "\n",
        "def make_prediction(image_path, model, model_path, file_to_write_path, height, width):\n",
        "  '''\n",
        "      This function makes the prediciton on new images.\n",
        "\n",
        "      Args:\n",
        "          image_path(str): path of images we want to predict the class for.\n",
        "          checkpoint_path(str): path of the stored weights from the fitted model.\n",
        "          model(): the model that has been fit and made by the training data.\n",
        "          height(int): height we want to resize the image to.\n",
        "          width(int): width we want to resize the image to.\n",
        "\n",
        "      Returns: A dictionary, classes of images.\n",
        "  '''\n",
        "  if(model):\n",
        "    model.load_weights(model_path)\n",
        "\n",
        "  else:\n",
        "    model = load_model(model_path)\n",
        "\n",
        "  files = [f for f in glob.glob(image_path + \"**/*.jpg\", recursive=True)]\n",
        "\n",
        "  images = []\n",
        "  filenames = []\n",
        "  actual_labels = []\n",
        "\n",
        "  for f in files:\n",
        "    with tf.io.gfile.GFile(f, 'rb') as fopen:\n",
        "        imge = fopen.read()\n",
        "    imge = tf.image.decode_image(imge)\n",
        "    w,h,d = imge.numpy().shape\n",
        "    image = tf.reshape(imge, (w, h, d))\n",
        "    image = preprocess(image,height, width, is_training=False)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    images.append(image)\n",
        "    filenames.append(f.rsplit('/', 1)[1])\n",
        "\n",
        "  images = np.vstack(images)\n",
        "  classes = model.predict_classes(images)\n",
        "  probabilities = model.predict_proba(images)\n",
        "  predicted_classes = []\n",
        "  for clas, fname, prob in zip(classes, filenames[3:], probabilities):\n",
        "    for name, lab in label_to_index.items():    \n",
        "      if lab == clas:\n",
        "        predicted_classes.append(tuple((fname, name, max(prob))))\n",
        "\n",
        "    with open(file_to_write_path + 'predicted_classes.txt', 'w') as fp:\n",
        "      fp.write('\\n'.join('%s %s %s' % x for x in predicted_classes))\n",
        "\n",
        "    \n",
        "  print(predicted_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdkCwgITvlM",
        "colab_type": "text"
      },
      "source": [
        "**Download and unzip the data calling 'downloadUnzip( )'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZhKKcopUCpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileName = 'flower_photos'\n",
        "#dest_dir = '/content/drive/My\\ Drive/project_phase4/dataset'\n",
        "dest_dir = '/content/sample_data/ML/dataset'\n",
        "\n",
        "sourceURL = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "data_root = downloadUnzip(fileName, sourceURL, dest_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ2r4QOlAGcm",
        "colab_type": "text"
      },
      "source": [
        "**Display Image & Caption calling 'display_image_and_caption( )'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UTiUThAAHR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_image_and_caption(data_root)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9uzv8yiAvfy",
        "colab_type": "text"
      },
      "source": [
        "**Split data into training, validation, testing by calling 'split_data()'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOOMJgxcAuBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 0.20\n",
        "valid_size = 0.20\n",
        "X_data = split_data(data_root, test_size, valid_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0SxiqqA9Xd",
        "colab_type": "text"
      },
      "source": [
        "**Make a dictionary of labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qfB02_GA-iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_index = class_dictionary(data_root)\n",
        "print(label_to_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ESIKy_HBHnu",
        "colab_type": "text"
      },
      "source": [
        "**Write the split data (above function) into three different files by calling 'write_dataset_to_file()'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOPPhJvzBJz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = ['trainData', 'testData', 'validataionData']\n",
        "root_file = '/content/sample_data/ML/dataset/'\n",
        "write_dataset_to_file(filenames, X_data, root_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDFBt5nrBMIk",
        "colab_type": "text"
      },
      "source": [
        "**Write data into tfrecords by calling 'write_tfrecords()'** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tjPaFqfBR7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/sample_data/ML/dataset/flower_photos/'\n",
        "write_tfrecords(data_dir, '/content/sample_data/ML/dataset/trainData.txt', '/content/sample_data/ML/dataset/trainImages.tfrecords') \n",
        "write_tfrecords(data_dir, '/content/sample_data/ML/dataset/validataionData.txt', '/content/sample_data/ML/dataset/testImages.tfrecords') \n",
        "write_tfrecords(data_dir, '/content/sample_data/ML/dataset/testData.txt', '/content/sample_data/ML/dataset/validImages.tfrecords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1G27l6qFqal",
        "colab_type": "text"
      },
      "source": [
        "**Dataset for each training, testing and validation are made with a specified batch size and shuffle buffer size by calling 'make_dataset()' three times**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9r9jygGBffh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle_buffer_size = 1000\n",
        "batch_size = 8\n",
        "ds_train = make_dataset('/content/sample_data/ML/dataset/trainImages.tfrecords', shuffle_buffer_size, batch_size, is_training=True, is_predict=False)\n",
        "ds_valid = make_dataset('/content/sample_data/ML/dataset/validImages.tfrecords', shuffle_buffer_size, batch_size, is_training=False, is_predict=False)\n",
        "ds_test = make_dataset('/content/sample_data/ML/dataset/testImages.tfrecords', shuffle_buffer_size, batch_size, is_training=False, is_predict=False)\n",
        "ds_test_predict = make_dataset('/content/sample_data/ML/dataset/testImages.tfrecords', shuffle_buffer_size, batch_size, is_training=False, is_predict=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrEnpb0rF1n2",
        "colab_type": "text"
      },
      "source": [
        "**Find number of steps to take per epoch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmWQLQHWFutw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = len(X_data[0])\n",
        "num_test = len(X_data[1])\n",
        "num_val = len(X_data[2])\n",
        "tr_steps_per_epoch = num_train//batch_size\n",
        "val_steps_per_epoch = num_val//batch_size\n",
        "te_steps_per_epoch = num_test//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRhKTFYLNKcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = 160\n",
        "w = 160\n",
        "amount = 4\n",
        "salt_vs_pepper = 0.2\n",
        "\n",
        "random_preprocessing = [{'normal': ['']}, {'random_flip': ['']}, {'random_crop':[h, w]}, {'random_brigthness': ['']}, {'random_salt_pepper': [amount, salt_vs_pepper]}]\n",
        "\n",
        "for images, labels in ds_train.take(1):\n",
        "  image1 = images[0]\n",
        "  image2 = augment(image1, random_preprocessing)\n",
        "  plt.imshow(image1.numpy(), interpolation='nearest')\n",
        "  plt.show()\n",
        "  plt.imshow(image2.numpy(), interpolation='nearest')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neno37N5MMrw",
        "colab_type": "text"
      },
      "source": [
        "**Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrgYjlK8F-jP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 160\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4qxO5m9M7_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_batch = base_model(images)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kVUTzulml8p",
        "colab_type": "text"
      },
      "source": [
        "**Freeze the convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVzVdVNimk7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESQtpIPVNtwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woga3_dWNBB9",
        "colab_type": "text"
      },
      "source": [
        "**Adding a classification head**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2xvqL-XN5mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7OErzwKN7Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(5)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZSSWYyCN924",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([base_model, global_average_layer, prediction_layer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jZ1jZBzmvKE",
        "colab_type": "text"
      },
      "source": [
        "**Compile the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i8bfScBOAeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fz_URlKlQ1C",
        "colab_type": "text"
      },
      "source": [
        "**Fit the model and make the confusion matrix for feature extraction.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYXyOvgJQmDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10\n",
        "validation_steps = 20\n",
        "log_dir=\"/content/sample_data/ML/models/feature_extraction/{}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "checkpoint_path = \"/content/sample_data/ML/models/training/cp.ckpt/{}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback, cp_callback, early_stop_callback = create_callbacks(log_dir, checkpoint_path)\n",
        "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
        "class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "history = model.fit(ds_train, epochs=initial_epochs, steps_per_epoch=tr_steps_per_epoch,validation_steps=val_steps_per_epoch, validation_data=ds_valid,callbacks=[tensorboard_callback, cp_callback, early_stop_callback, ConfusionMatrixLogger(ds_train, file_writer_cm, class_names, val_steps_per_epoch)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJDVOZGbMo2v",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRXpzq34LJsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_predict = ds_test_predict\n",
        "dataset_eval = ds_test\n",
        "steps = te_steps_per_epoch\n",
        "file_to_write = '/content/sample_data/ML/'\n",
        "model_path = checkpoint_path\n",
        "accuracy, precision, recall = evaluate_model(model, model_path, dataset_eval, dataset_predict, steps, file_to_write)\n",
        "\n",
        "print('Accuracy: ' + str(accuracy))\n",
        "print('Precision: ' + str(precision))\n",
        "print('Recall: ' + str(recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFD2Gf72labI",
        "colab_type": "text"
      },
      "source": [
        "**Plot accuracy and loss for Feature Extraction.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0n-IsEBRUno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1uL3Fezlngz",
        "colab_type": "text"
      },
      "source": [
        "**Display TensorBoard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Xp1FWKVDPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir /content/sample_data/ML/models/feature_extraction/\n",
        "%tensorboard --logdir {log_dir}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDeBR6Eu0yMU",
        "colab_type": "text"
      },
      "source": [
        "**Make Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pNvQgUk0xx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = '/content/sample_data/ML/dataset/flower_photos/daisy/'\n",
        "file_to_write_path = '/content/sample_data/ML/'\n",
        "height = 160\n",
        "width = 160\n",
        "model_path = checkpoint_path\n",
        "make_prediction(image_path, model, model_path, file_to_write_path, height, width)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mvrVWvRYi5-",
        "colab_type": "text"
      },
      "source": [
        "**Fine Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7uw6khdm4qr",
        "colab_type": "text"
      },
      "source": [
        "**Un-freeze the top layers of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV8l1e1gYaYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaVbWqIHYw7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of layers in the base model:\", len(base_model.layers))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9svez8YyGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_tune_at = 100\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guy27IQpm7xO",
        "colab_type": "text"
      },
      "source": [
        "**Compile the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7kfyJVY-UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10), metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sRhFH-IZA-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Ejs8n0luJB",
        "colab_type": "text"
      },
      "source": [
        "**Fit the model and construct confusion matrix for Fine Tuning.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lFIP2qtZG_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "log_dir=\"/content/sample_data/ML/models/fine_tune/{}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "checkpoint_path = \"/content/sample_data/ML/models/training/cp.ckpt/{}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback, cp_callback, early_stop_callback = create_callbacks(log_dir, checkpoint_path)\n",
        "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm_ft')\n",
        "fine_history = model.fit(ds_train, epochs=initial_epochs, steps_per_epoch=tr_steps_per_epoch,validation_steps=val_steps_per_epoch, validation_data=ds_valid,callbacks=[tensorboard_callback, cp_callback ,ConfusionMatrixLogger(ds_train, file_writer_cm, class_names, val_steps_per_epoch)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGdLqxWWl2E8",
        "colab_type": "text"
      },
      "source": [
        "**Plot accuracy and loss for fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsAm7sN-Zpmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc += fine_history.history['accuracy']\n",
        "val_acc += fine_history.history['val_accuracy']\n",
        "\n",
        "loss += fine_history.history['loss']\n",
        "val_loss += fine_history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "#plt.ylim([0.8, 1])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "#plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KcxLgGl8VW",
        "colab_type": "text"
      },
      "source": [
        "**Display TensorBoard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trayR0fidgEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir /content/sample_data/ML/models/fine_tune/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}